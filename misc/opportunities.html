<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN">
<html>
<head>
  <title>opportunities</title>
  	<link rel="stylesheet" href="../styles/mystyles.css">
  </head>

<body>

<!-- Site navigation menu -->

<div class="navbar-container">
  <nav>
  <a href="../index.html">Home page</a>
  <a href="topic.html">Technology/Topic</a>
	<a href="opportunities.html">Opportunities</a>
	<a href="risks.html">Risks</a>
	<a href="choices.html">Choices</a>
	<a href="ethics.html">Ethical Reflections</a>
	<a href="references.html">References</a>
   <a href="process.html">Process Support</a>
   </div>
  </nav>

<!-- Main content -->
<div class="container">
<h1>AI-Generated Music Opportunities</h1>
<img src="../images/opportunities.jpg" alt="opportunities" width="600px">
<h2>Opportunities of AI-Generated Music</h2>

<p>With the unparalleled growth of technology in recent years, Artificial Intelligence has now converged with the Music Industry, presenting different opportunities that AI could unlock in the Music Industry for innovation, creativity and creativity. One such opportunity that Artificial Intelligence could bring to the music industry is the ability to produce music much quicker and more efficiently than ever. Another opportunity that AI can bring to music is through revolutionizing Music discovery and music recommendation systems. Using context-based AI systems, music streaming platforms will be able to enhance music recommendation based on the users' personal preferences allowing for more user engagement and enjoyment through new music discoveries. AI Generated music could also be used as a tool to improve mental health and general mental wellbeing. It has been proven that music influences emotions and behaviours of Humans, therefore with AI, music could be specifically generated to help with mental health issues such as anxiety and increase overall moods. The final opportunity that AI presents to music is enhancing live music performances. Using AI, performers will be able to implement real-time adjustments or improvisations to their show, enhancing the uniqueness and creativity of the show and improving the experience for the fans. </p>
<p>With the insurgence of AI in music, it offers the opportunity for musicians to speed up and optimize the production process while keeping the creativity of the art intact. Using deep learning methods like deep neural networks AI can generate beats, pick samples, edit audio in several different ways and even generate lyrics. AI models like DeepJ have been trained to use deep neural networks to generate music in specific artistic styles and musical genres. Another example of An AI model that artists could use to help the efficiency of their work is Youling, which is an AI-assisted lyrics creation system designed to collaborate with musicians and aid them in writing and polishing lyrics. These AI models can be utilized by musicians and artists to compose songs in whatever style they want allowing them to save a lot of time on repetitive tasks like producing the beat, mixing audio, and writing lyrics. </p>

<p>Another opportunity that AI has brought to the music industry is the possibility of revolutionizing music discovery and recommendation for users. In today's scene it can be hard for listeners to access or find new music as there is just so many options available in the ever-growing catalogue of music woldwide. Using context-aware AI systems this problem could potentially be resolved as context-aware systems consider factors such as age, gender, language, culture, and location of listeners along with genre and stylistic preferences to suggest music that is specifically tailored for them. Music streaming platforms such as Spotify and Apple music have already begun to introduce AI onto their platforms through machine learning systems which recommend music to listeners. However, streaming platforms have yet to utilize a context-aware AI model. Implementing such a model would be much more effective than current systems in providing recommendations to users, as context-aware models help to provide more personalized and dynamic recommendations to the user which would help with user engagement and provide an overall more tailored and individualistic experience for the user. Streaming platforms could also benefit from the implementation of context-aware AI models, as it could help users discover new lesser-known artists and songs that they would have never heard before, which benefits the listeners, the artists, and the platforms. </p>

<p>Artificial Intelligence can also be utilized by musicians to enhance their live shows and concerts, creating new possibilities to improve experiences for both artists and their audiences. AI could be used during live performances to provide real-time improvisation for any adjustments that the artist wants to make to their show. This could be done using AI systems that involve a method called Generation in Context. Examples of such AI systems that use this are LEMu (live electronic music) and JamBot (improvisatory accompaniment agent). Both systems work by taking an analysis of existing music and generating new music to go alongside it, these systems have also been created with the vision of being interacted with by musicians during live performances. LEMu works by analysing a MIDI file provided by the musician and generates numerous transitional options between tracks provided by the musician. This process is controlled in the performance through a MorphTable which allows musicians to manipulate the parameters of the music to their preference live. This option would be very good for musicians and DJs who create electronic music and are inexperienced in transitioning between tracks. JamBot on the other hand works by listening to an audio source and generating new sounds to play along with the source. It analyzes the audio and stores many different representations of the audio at once in what is called the Chimera Architecture which can be accessed by the performer to choose what variation of the track they want to play. Both options would be very beneficial to live performers as they can help enhance the experience at each show by altering their music slightly differently every time, giving the feeling of a personalized and unique experience to the audience and even the musicians. </p>

<p>Since as early as 1789 music has been understood to have an influence the human mind and include therapeutic properties, since then the idea of music therapy has been extensively researched an experimented with and has been scientifically proven to work on people with mental health issues such as depression and anxiety. However, in this new age of technology a new opportunity has developed for Artificial Intelligence to generate music which includes these therapeutic properties to make music therapy an accessible option for struggling people around the world. Using the techniques of machine learning Artificial Intelligence can be used to generate music that has the potential to produce therapeutic soundtracks based on a listener's bio-signals, providing them with the assistance that their body and mind needs to stay relaxed, positive and happy when faced with mental health problems such as anxiety, depression, stress and general wellbeing. </p>
</div>


<address>Made 4 June 2023<br>

  
  Written by Aidan King</address>
</body>
</html>